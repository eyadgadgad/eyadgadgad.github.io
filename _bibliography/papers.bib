---
---

@string{aps = {American Physical Society,}}

@ARTICLE{10618889,
  author={Gad, Gad and Gad, Eyad and Fadlullah, Zubair Md and Fouda, Mostafa M. and Kato, Nei},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Communication-Efficient and Privacy-Preserving Federated Learning via Joint Knowledge Distillation and Differential Privacy in Bandwidth-Constrained Networks}, 
  year={2024},
  volume={73},
  number={11},
  pages={17586-17601},
  keywords={Servers;Data models;Training;Federated learning;Distributed databases;Deep learning;Accuracy;B5G networks;deep learning;differential privacy;federated learning;gradient compression;heterogeneous federated learning;knowledge distillation},
  doi={10.1109/TVT.2024.3423718}}


@INPROCEEDINGS{10577749,
  author={Gad, Eyad and Fadlullah, Zubair Md and Fouda, Mostafa M.},
  booktitle={2024 International Conference on Smart Applications, Communications and Networking (SmartNets)}, 
  title={A Robust Federated Learning Approach for Combating Attacks Against IoT Systems Under Non-IID Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  keywords={Training;Accuracy;Federated learning;Scalability;Computational modeling;Robustness;Internet of Things;Internet of Things (IoT);Federated Learning (FL);non-IID data;statistical heterogeneity;Intrusion Detection System (IDS);scaffolding technique},
  doi={10.1109/SmartNets61466.2024.10577749}}


@InProceedings{10.1007/978-3-031-49333-1_18,
author="Gad, Eyad
and Soliman, Seif
and Darweesh, M. Saeed",
editor="Mosbah, Mohamed
and Kechadi, Tahar
and Bellatreche, Ladjel
and Gargouri, Faiez",
title="Advancing Brain Tumor Segmentation via Attention-Based 3D U-Net Architecture and Digital Image Processing",
booktitle="Model and Data Engineering",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="245--258",
abstract="In the realm of medical diagnostics, rapid advancements in Artificial Intelligence (AI) have significantly yielded remarkable improvements in brain tumor segmentation. Encoder-Decoder architectures, such as U-Net, have played a transformative role by effectively extracting meaningful representations in 3D brain tumor segmentation from Magnetic resonance imaging (MRI) scans. However, standard U-Net models encounter challenges in accurately delineating tumor regions, especially when dealing with irregular shapes and ambiguous boundaries. Additionally, training robust segmentation models on high-resolution MRI data, such as the BraTS datasets, necessitates high computational resources and often faces challenges associated with class imbalance. This study proposes the integration of the attention mechanism into the 3D U-Net model, enabling the model to capture intricate details and prioritize informative regions during the segmentation process. Additionally, a tumor detection algorithm based on digital image processing techniques is utilized to address the issue of imbalanced training data and mitigate bias. This study aims to enhance the performance of brain tumor segmentation, ultimately improving the reliability of diagnosis. The proposed model is thoroughly evaluated and assessed on the BraTS 2020 dataset using various performance metrics to accomplish this goal. The obtained results indicate that the model outperformed related studies, exhibiting dice of 0.975, specificity of 0.988, and sensitivity of 0.995, indicating the efficacy of the proposed model in improving brain tumor segmentation, offering valuable insights for reliable diagnosis in clinical settings.",
isbn="978-3-031-49333-1"
}

@InProceedings{10.1007/978-3-031-48593-0_23,
author="Gad, Eyad
and Abou Khatwa, Mustafa
and A. Elattar, Mustafa
and Selim, Sahar",
editor="Waiter, Gordon
and Lambrou, Tryphon
and Leontidis, Georgios
and Oren, Nir
and Morris, Teresa
and Gordon, Sharon",
title="A Novel Approach to Breast Cancer Segmentation Using U-Net Model with Attention Mechanisms and FedProx",
booktitle="Medical Image Understanding and Analysis",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="310--324",
abstract="Breast cancer is a leading cause of death among women worldwide, emphasizing the need for early detection and accurate diagnosis. As such Ultrasound Imaging, a reliable and cost-effective tool, is used for this purpose, however the sensitive nature of medical data makes it challenging to develop accurate and private artificial intelligence models. A solution is Federated Learning as it is a promising technique for distributed machine learning on sensitive medical data while preserving patient privacy. However, training on non-Independent and non-Identically Distributed (non-IID) local datasets can impact the accuracy and generalization of the trained model, which is crucial for accurate tumour boundary delineation in BC segmentation. This study aims to tackle this challenge by applying the Federated Proximal (FedProx) method to non-IID Ultrasonic Breast Cancer Imaging datasets. Moreover, we focus on enhancing tumour segmentation accuracy by incorporating a modified U-Net model with attention mechanisms. Our approach resulted in a global model with 96{\%} accuracy, demonstrating the effectiveness of our method in enhancing tumour segmentation accuracy while preserving patient privacy. Our findings suggest that FedProx has the potential to be a promising approach for training precise machine learning models on non-IID local medical datasets.",
isbn="978-3-031-48593-0"
}


@InProceedings{10.1007/978-3-031-21595-7_3,
author="Gad, Eyad
and Gamal, Aya
and Elattar, Mustafa
and Selim, Sahar",
editor="Fournier-Viger, Philippe
and Hassan, Ahmed
and Bellatreche, Ladjel",
title="A Novel Diagnostic Model for Early Detection of Alzheimer's Disease Based on Clinical and Neuroimaging Features",
booktitle="Model and Data Engineering",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="26--39",
abstract="Alzheimer's Disease (AD) is a dangerous disease that is known for its characteristics of eroding memory and destroying the brain. The classification of Alzheimer's disease is an important topic that has recently been addressed by many studies using Machine Learning (ML) and Deep Learning (DL) methods. Most research papers tackling early diagnosis of AD use these methods as a feature extractor for neuroimaging data. In our research paper, the proposed algorithm is to optimize the performance of the prediction of early diagnosis from the multimodal dataset by a multi-step framework that uses a Deep Neural Network (DNN) as an optimization technique to extract features and train these features by Random Forest (RF) classifier. The results of the proposed algorithm showed that using only demographic and clinical data results in a balanced accuracy of 88{\%} and an area under the curve (AUC) of 94.6. Ultimately, combining clinical and neuroimaging features, prediction results improved further to a balanced accuracy of 92{\%} and an AUC of 97{\%}. This study successfully outperformed other studies for both clinical and the combination of clinical and neuroimaging data, proving that multimodal data is efficient in the early diagnosis of AD.",
isbn="978-3-031-21595-7"
}


@Article{electronics11111785,
AUTHOR = {Gad, Gad and Gad, Eyad and Cengiz, Korhan and Fadlullah, Zubair and Mokhtar, Bassem},
TITLE = {Deep Learning-Based Context-Aware Video Content Analysis on IoT Devices},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {11},
ARTICLE-NUMBER = {1785},
URL = {https://www.mdpi.com/2079-9292/11/11/1785},
ISSN = {2079-9292},
ABSTRACT = {Integrating machine learning with the Internet of Things (IoT) enables many useful applications. For IoT applications that incorporate video content analysis (VCA), deep learning models are usually used due to their capacity to encode the high-dimensional spatial and temporal representations of videos. However, limited energy and computation resources present a major challenge. Video captioning is one type of VCA that describes a video with a sentence or a set of sentences. This work proposes an IoT-based deep learning-based framework for video captioning that can (1) Mine large open-domain video-to-text datasets to extract video-caption pairs that belong to a particular domain. (2) Preprocess the selected video-caption pairs including reducing the complexity of the captions’ language model to improve performance. (3) Propose two deep learning models: A transformer-based model and an LSTM-based model. Hyperparameter tuning is performed to select the best hyperparameters. Models are evaluated in terms of accuracy and inference time on different platforms. The presented framework generates captions in standard sentence templates to facilitate extracting information in later stages of the analysis. The two developed deep learning models offer a trade-off between accuracy and speed. While the transformer-based model yields a high accuracy of 97%, the LSTM-based model achieves near real-time inference.},
DOI = {10.3390/electronics11111785}
}



